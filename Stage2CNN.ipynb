{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/toka-amer/Handwritten-Signature-Verification/blob/main/Stage2CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k3jq-w9BOyLM",
        "outputId": "5d90f401-2fd7-49f5-c430-84a3d1cb1518"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tflearn\n",
            "  Downloading tflearn-0.5.0.tar.gz (107 kB)\n",
            "\u001b[K     |████████████████████████████████| 107 kB 7.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from tflearn) (1.21.6)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from tflearn) (1.15.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.8/dist-packages (from tflearn) (7.1.2)\n",
            "Building wheels for collected packages: tflearn\n",
            "  Building wheel for tflearn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for tflearn: filename=tflearn-0.5.0-py3-none-any.whl size=127299 sha256=92ad6aac6e61f0c309a29027cade40dd8c2727e56ef6c0b5f80a465b1d3d7103\n",
            "  Stored in directory: /root/.cache/pip/wheels/65/9b/15/cb1e6b279c14ed897530d15cfd7da8e3df8a947e593f5cfe59\n",
            "Successfully built tflearn\n",
            "Installing collected packages: tflearn\n",
            "Successfully installed tflearn-0.5.0\n"
          ]
        }
      ],
      "source": [
        "! pip install tflearn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OVlpeqrYPBwV",
        "outputId": "1f17582e-77b9-4576-894f-2198be9ed517"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/compat/v2_compat.py:107: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "non-resource variables are not supported in the long term\n"
          ]
        }
      ],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "from random import shuffle\n",
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import tflearn\n",
        "from tflearn.layers.conv import conv_2d, max_pool_2d\n",
        "from tflearn.layers.core import input_data, dropout, fully_connected\n",
        "from tflearn.layers.estimator import regression\n",
        "from tensorflow.python.framework import ops\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ST_W-XdrPGAU",
        "outputId": "0b68b85c-47b6-40f8-b499-391de590e7ae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VFLiR-FzPM89"
      },
      "outputs": [],
      "source": [
        "path='/content/drive/MyDrive/vision_data'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bhuGHDBcP4k-"
      },
      "outputs": [],
      "source": [
        "PersonA_DIR_Train = '/content/drive/MyDrive/vision_data/personA/Train'\n",
        "PersonA_DIR_Test = '/content/drive/MyDrive/vision_data/personA/Test'\n",
        "PersonB_DIR_Train = '/content/drive/MyDrive/vision_data/personB/Train'\n",
        "PersonB_DIR_Test = '/content/drive/MyDrive/vision_data/personB/Test'\n",
        "PersonC_DIR_Train = '/content/drive/MyDrive/vision_data/personC/Train'\n",
        "PersonC_DIR_Test = '/content/drive/MyDrive/vision_data/personC/Test'\n",
        "PersonD_DIR_Train = '/content/drive/MyDrive/vision_data/personD/Train'\n",
        "PersonD_DIR_Test = '/content/drive/MyDrive/vision_data/personD/Test'\n",
        "PersonE_DIR_Train = '/content/drive/MyDrive/vision_data/personE/Train'\n",
        "PersonE_DIR_Test = '/content/drive/MyDrive/vision_data/personE/Test'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bXvd4hu4P6gp"
      },
      "outputs": [],
      "source": [
        "IMG_SIZE =50\n",
        "LR = 0.001\n",
        "MODEL_PersonA_NAME = 'fake-vs-real-personA-cnn'\n",
        "MODEL_PersonB_NAME = 'fake-vs-real-personB-cnn'\n",
        "MODEL_PersonC_NAME = 'fake-vs-real-personC-cnn'\n",
        "MODEL_PersonD_NAME = 'fake-vs-real-personD-cnn'\n",
        "MODEL_PersonE_NAME = 'fake-vs-real-personE-cnn'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ql_91DU-QFaM"
      },
      "outputs": [],
      "source": [
        "def get_label(ImageName,path):\n",
        "   all_files=pd.read_csv(path)\n",
        "   all_files = np.array(all_files)\n",
        "   found='false'\n",
        "   for i in range(len(all_files)):\n",
        "     if all_files[i][0]==ImageName:\n",
        "       found='true'\n",
        "       if all_files[i][1]==\"forged\":\n",
        "         return np.array([0,1])\n",
        "       elif all_files[i][1]==\"real\":\n",
        "         return np.array([1,0])\n",
        "   if found=='false':\n",
        "     return np.array([0,1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A9i8nJ0KcSLZ"
      },
      "outputs": [],
      "source": [
        "def create_personA_train_data():\n",
        "  PersonA_train_data = []\n",
        "\n",
        "  for img in tqdm(os.listdir(PersonA_DIR_Train)):\n",
        "         path = os.path.join(PersonA_DIR_Train, img)\n",
        "         img_data = cv2.imread(path, 0)\n",
        "         if img_data is None:\n",
        "             print('train Wrong path:', path)\n",
        "         else:\n",
        "             img_data = cv2.resize(img_data, (IMG_SIZE,IMG_SIZE))\n",
        "             PersonA_train_data.append(\n",
        "                 [np.array(img_data), get_label(img, '/content/drive/MyDrive/vision_data/personA/Train/personA_SigVerificationTrainLabels.csv')])\n",
        "\n",
        "  shuffle(PersonA_train_data)\n",
        "  np.save('PersonA_train_data.npy', PersonA_train_data)\n",
        "  return PersonA_train_data   "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TJ1Acu0Uc2j8"
      },
      "outputs": [],
      "source": [
        "def create_personB_train_data():\n",
        "  PersonB_train_data = []\n",
        "\n",
        "  for img in tqdm(os.listdir(PersonB_DIR_Train)):\n",
        "         path = os.path.join(PersonB_DIR_Train, img)\n",
        "         img_data = cv2.imread(path, 0)\n",
        "         if img_data is None:\n",
        "             print('train Wrong path:', path)\n",
        "         else:\n",
        "             img_data = cv2.resize(img_data, (IMG_SIZE,IMG_SIZE))\n",
        "             PersonB_train_data.append(\n",
        "                 [np.array(img_data), get_label(img, '/content/drive/MyDrive/vision_data/personB/Train/personB_SigVerificationTrainLabels.csv')])\n",
        "\n",
        "  shuffle(PersonB_train_data)\n",
        "  np.save('PersonB_train_data.npy', PersonB_train_data)\n",
        "  return PersonB_train_data  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OW9qrBPodIFo"
      },
      "outputs": [],
      "source": [
        "def create_personC_train_data():\n",
        "  PersonC_train_data = []\n",
        "\n",
        "  for img in tqdm(os.listdir(PersonC_DIR_Train)):\n",
        "         path = os.path.join(PersonC_DIR_Train, img)\n",
        "         img_data = cv2.imread(path, 0)\n",
        "         if img_data is None:\n",
        "             print('train Wrong path:', path)\n",
        "         else:\n",
        "             img_data = cv2.resize(img_data, (IMG_SIZE,IMG_SIZE))\n",
        "             PersonC_train_data.append(\n",
        "                 [np.array(img_data), get_label(img, '/content/drive/MyDrive/vision_data/personC/Train/personC_SigVerificationTrainLabels.csv')])\n",
        "\n",
        "  shuffle(PersonC_train_data)\n",
        "  np.save('PersonC_train_data.npy', PersonC_train_data)\n",
        "  return PersonC_train_data  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0cWUCB6JdUIF"
      },
      "outputs": [],
      "source": [
        "def create_personD_train_data():\n",
        "  PersonD_train_data = []\n",
        "\n",
        "  for img in tqdm(os.listdir(PersonD_DIR_Train)):\n",
        "         path = os.path.join(PersonD_DIR_Train, img)\n",
        "         img_data = cv2.imread(path, 0)\n",
        "         if img_data is None:\n",
        "             print('train Wrong path:', path)\n",
        "         else:\n",
        "             img_data = cv2.resize(img_data, (IMG_SIZE,IMG_SIZE))\n",
        "             PersonD_train_data.append(\n",
        "                 [np.array(img_data), get_label(img, '/content/drive/MyDrive/vision_data/personD/Train/personD_SigVerificationTrainLabels.csv')])\n",
        "\n",
        "  shuffle(PersonD_train_data)\n",
        "  np.save('PersonD_train_data.npy', PersonD_train_data)\n",
        "  return PersonD_train_data  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sED9QDK1dgRk"
      },
      "outputs": [],
      "source": [
        "def create_personE_train_data():\n",
        "  PersonE_train_data = []\n",
        "\n",
        "  for img in tqdm(os.listdir(PersonE_DIR_Train)):\n",
        "         path = os.path.join(PersonE_DIR_Train, img)\n",
        "         img_data = cv2.imread(path, 0)\n",
        "         if img_data is None:\n",
        "             print('train Wrong path:', path)\n",
        "         else:\n",
        "             img_data = cv2.resize(img_data, (IMG_SIZE,IMG_SIZE))\n",
        "             PersonE_train_data.append(\n",
        "                 [np.array(img_data), get_label(img, '/content/drive/MyDrive/vision_data/personE/Train/personE_SigVerificationTrainLabels.csv')])\n",
        "\n",
        "  shuffle(PersonE_train_data)\n",
        "  np.save('PersonE_train_data.npy', PersonE_train_data)\n",
        "  return PersonE_train_data  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "reinD_0Pdr81"
      },
      "outputs": [],
      "source": [
        "def create_personA_test_data():\n",
        "  PersonA_test_data = []\n",
        "\n",
        "  for img in tqdm(os.listdir(PersonA_DIR_Test)):\n",
        "         path = os.path.join(PersonA_DIR_Test, img)\n",
        "         img_data = cv2.imread(path, 0)\n",
        "         if img_data is None:\n",
        "             print('train Wrong path:', path)\n",
        "         else:\n",
        "             img_data = cv2.resize(img_data, (IMG_SIZE,IMG_SIZE))\n",
        "             PersonA_test_data.append(\n",
        "                 [np.array(img_data), get_label(img, '/content/drive/MyDrive/vision_data/personA/Test/personA_SigVerificationTestLabels.csv')])\n",
        "\n",
        "  shuffle(PersonA_test_data)\n",
        "  np.save('PersonA_test_data.npy', PersonA_test_data)\n",
        "  return PersonA_test_data  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W9oWjPEKd9Ie"
      },
      "outputs": [],
      "source": [
        "def create_personB_test_data():\n",
        "  PersonB_test_data = []\n",
        "\n",
        "  for img in tqdm(os.listdir(PersonB_DIR_Test)):\n",
        "         path = os.path.join(PersonB_DIR_Test, img)\n",
        "         img_data = cv2.imread(path, 0)\n",
        "         if img_data is None:\n",
        "             print('train Wrong path:', path)\n",
        "         else:\n",
        "             img_data = cv2.resize(img_data, (IMG_SIZE,IMG_SIZE))\n",
        "             PersonB_test_data.append(\n",
        "                 [np.array(img_data), get_label(img, '/content/drive/MyDrive/vision_data/personB/Test/personB_SigVerificationTestLabels.csv')])\n",
        "\n",
        "  shuffle(PersonB_test_data)\n",
        "  np.save('PersonB_test_data.npy', PersonB_test_data)\n",
        "  return PersonB_test_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D27ZiI1keRDx"
      },
      "outputs": [],
      "source": [
        "def create_personC_test_data():\n",
        "  PersonC_test_data = []\n",
        "\n",
        "  for img in tqdm(os.listdir(PersonC_DIR_Test)):\n",
        "         path = os.path.join(PersonC_DIR_Test, img)\n",
        "         img_data = cv2.imread(path, 0)\n",
        "         if img_data is None:\n",
        "             print('train Wrong path:', path)\n",
        "         else:\n",
        "             img_data = cv2.resize(img_data, (IMG_SIZE,IMG_SIZE))\n",
        "             PersonC_test_data.append(\n",
        "                 [np.array(img_data), get_label(img, '/content/drive/MyDrive/vision_data/personC/Test/personC_SigVerificationTestLabels.csv')])\n",
        "\n",
        "  shuffle(PersonC_test_data)\n",
        "  np.save('PersonC_test_data.npy', PersonC_test_data)\n",
        "  return PersonC_test_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fxt3mKiQecLn"
      },
      "outputs": [],
      "source": [
        "def create_personD_test_data():\n",
        "  PersonD_test_data = []\n",
        "\n",
        "  for img in tqdm(os.listdir(PersonD_DIR_Test)):\n",
        "         path = os.path.join(PersonD_DIR_Test, img)\n",
        "         img_data = cv2.imread(path, 0)\n",
        "         if img_data is None:\n",
        "             print('train Wrong path:', path)\n",
        "         else:\n",
        "             img_data = cv2.resize(img_data, (IMG_SIZE,IMG_SIZE))\n",
        "             PersonD_test_data.append(\n",
        "                 [np.array(img_data), get_label(img, '/content/drive/MyDrive/vision_data/personD/Test/personD_SigVerificationTestLabels.csv')])\n",
        "\n",
        "  shuffle(PersonD_test_data)\n",
        "  np.save('PersonD_test_data.npy', PersonD_test_data)\n",
        "  return PersonD_test_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IavfzOLGenI0"
      },
      "outputs": [],
      "source": [
        "def create_personE_test_data():\n",
        "  PersonE_test_data = []\n",
        "\n",
        "  for img in tqdm(os.listdir(PersonE_DIR_Test)):\n",
        "         path = os.path.join(PersonE_DIR_Test, img)\n",
        "         img_data = cv2.imread(path, 0)\n",
        "         if img_data is None:\n",
        "             print('train Wrong path:', path)\n",
        "         else:\n",
        "             img_data = cv2.resize(img_data, (IMG_SIZE,IMG_SIZE))\n",
        "             PersonE_test_data.append(\n",
        "                 [np.array(img_data), get_label(img, '/content/drive/MyDrive/vision_data/personE/Test/personE_SigVerificationTestLabels.csv')])\n",
        "\n",
        "  shuffle(PersonE_test_data)\n",
        "  np.save('PersonE_test_data.npy', PersonE_test_data)\n",
        "  return PersonE_test_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YFnWe_e7bfBH",
        "outputId": "0380c0e3-6ecd-4544-b7f4-0e37222b4e65"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 41/41 [00:09<00:00,  4.29it/s]\n",
            "/usr/local/lib/python3.8/dist-packages/numpy/lib/npyio.py:528: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  arr = np.asanyarray(arr)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train Wrong path: /content/drive/MyDrive/vision_data/personA/Train/personA_SigVerificationTrainLabels.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 9/9 [00:02<00:00,  4.33it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train Wrong path: /content/drive/MyDrive/vision_data/personA/Test/personA_SigVerificationTestLabels.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "#if (os.path.exists('PersonA_train_data.npy')): # If you have already created the dataset:\n",
        "    # PersonA_train_data =np.load('PersonA_train_data.npy',allow_pickle=True)\n",
        "#else: # If dataset is not created:\n",
        "\n",
        "PersonA_train_data = create_personA_train_data()\n",
        "\n",
        "#if (os.path.exists('PersonA_test_data.npy')):\n",
        "    # PersonA_test_data =np.load('PersonA_test_data.npy',allow_pickle=True)\n",
        "#else:\n",
        "PersonA_test_data = create_personA_test_data()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eMLZiSwzfb7-",
        "outputId": "dc8bf906-cc28-430e-eb20-086eb7c8ffe4"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 41/41 [00:09<00:00,  4.37it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train Wrong path: /content/drive/MyDrive/vision_data/personB/Train/personB_SigVerificationTrainLabels.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 9/9 [00:02<00:00,  4.38it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train Wrong path: /content/drive/MyDrive/vision_data/personB/Test/personB_SigVerificationTestLabels.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "#if (os.path.exists('PersonB_train_data.npy')): # If you have already created the dataset:\n",
        "    # PersonB_train_data =np.load('PersonB_train_data.npy',allow_pickle=True)\n",
        "#else: # If dataset is not created:\n",
        "\n",
        "PersonB_train_data = create_personB_train_data()\n",
        "\n",
        "#if (os.path.exists('PersonB_test_data.npy')):\n",
        "     #PersonB_test_data =np.load('PersonB_test_data.npy',allow_pickle=True)\n",
        "#else:\n",
        "PersonB_test_data = create_personB_test_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T3pHgZvJfpia",
        "outputId": "9f724c1f-5aff-4ba7-e208-3bb5febd24d2"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 41/41 [00:09<00:00,  4.43it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train Wrong path: /content/drive/MyDrive/vision_data/personC/Train/personC_SigVerificationTrainLabels.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 9/9 [00:02<00:00,  4.41it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train Wrong path: /content/drive/MyDrive/vision_data/personC/Test/personC_SigVerificationTestLabels.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "#if (os.path.exists('PersonC_train_data.npy')): # If you have already created the dataset:\n",
        "     #PersonC_train_data =np.load('PersonC_train_data.npy',allow_pickle=True)\n",
        "#else: # If dataset is not created:\n",
        "PersonC_train_data = create_personC_train_data()\n",
        "\n",
        "#if (os.path.exists('PersonC_test_data.npy')):\n",
        "     #PersonC_test_data =np.load('PersonC_test_data.npy',allow_pickle=True)\n",
        "PersonC_test_data = create_personC_test_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GzaFC9Gxf5ZW",
        "outputId": "1a00b185-10ee-4b16-fe3e-6e6ac1804a91"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 41/41 [00:09<00:00,  4.33it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train Wrong path: /content/drive/MyDrive/vision_data/personD/Train/personD_SigVerificationTrainLabels.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 9/9 [00:02<00:00,  4.11it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train Wrong path: /content/drive/MyDrive/vision_data/personD/Test/personD_SigVerificationTestLabels.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "#if (os.path.exists('PersonD_train_data.npy')): # If you have already created the dataset:\n",
        "    # PersonD_train_data =np.load('PersonD_train_data.npy',allow_pickle=True)\n",
        "#else: # If dataset is not created:\n",
        "PersonD_train_data = create_personD_train_data()\n",
        "\n",
        "#if (os.path.exists('PersonD_test_data.npy')):\n",
        "     #PersonD_test_data =np.load('PersonD_test_data.npy',allow_pickle=True)\n",
        "#else:\n",
        "PersonD_test_data = create_personD_test_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j6jAdSF-gHAz",
        "outputId": "11d2c0bb-ae4a-4947-93e2-c43cf004ad0d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 51/51 [00:11<00:00,  4.31it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train Wrong path: /content/drive/MyDrive/vision_data/personE/Train/personE_SigVerificationTrainLabels.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 9/9 [00:02<00:00,  4.38it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train Wrong path: /content/drive/MyDrive/vision_data/personE/Test/personE_SigVerificationTestLabels.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "#if (os.path.exists('PersonE_train_data.npy')): # If you have already created the dataset:\n",
        "     #PersonE_train_data =np.load('PersonE_train_data.npy',allow_pickle=True)\n",
        "#else: # If dataset is not created:\n",
        "PersonE_train_data = create_personE_train_data()\n",
        "\n",
        "#if (os.path.exists('PersonE_test_data.npy')):\n",
        "   #  PersonE_test_data =np.load('PersonE_test_data.npy',allow_pickle=True)\n",
        "#else:\n",
        "PersonE_test_data = create_personE_test_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ecJ_tx_Ghdny"
      },
      "outputs": [],
      "source": [
        "X_PersonA_train = np.array([i[0] for i in PersonA_train_data]).reshape(-1,IMG_SIZE,IMG_SIZE, 1)\n",
        "y_PersonA_train = np.array([i[1] for i in PersonA_train_data])\n",
        "\n",
        "X_PersonA_test = np.array([i[0] for i in PersonA_test_data]).reshape(-1, IMG_SIZE, IMG_SIZE, 1)\n",
        "y_PersonA_test = np.array([i[1] for i in PersonA_test_data])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eNPyLXwHiJBb"
      },
      "outputs": [],
      "source": [
        "X_PersonB_train = np.array([i[0] for i in PersonB_train_data]).reshape(-1, IMG_SIZE, IMG_SIZE, 1)\n",
        "y_PersonB_train = np.array([i[1] for i in PersonB_train_data])\n",
        "\n",
        "X_PersonB_test = np.array([i[0] for i in PersonB_test_data]).reshape(-1, IMG_SIZE, IMG_SIZE, 1)\n",
        "y_PersonB_test = np.array([i[1] for i in PersonB_test_data])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yED-mKqXiSnx"
      },
      "outputs": [],
      "source": [
        "X_PersonC_train = np.array([i[0] for i in PersonC_train_data]).reshape(-1, IMG_SIZE, IMG_SIZE, 1)\n",
        "y_PersonC_train = np.array([i[1] for i in PersonC_train_data])\n",
        "\n",
        "X_PersonC_test = np.array([i[0] for i in PersonC_test_data]).reshape(-1,IMG_SIZE, IMG_SIZE, 1)\n",
        "y_PersonC_test = np.array([i[1] for i in PersonC_test_data])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uh4HxdiFiaQC"
      },
      "outputs": [],
      "source": [
        "X_PersonD_train = np.array([i[0] for i in PersonD_train_data]).reshape(-1, IMG_SIZE,IMG_SIZE, 1)\n",
        "y_PersonD_train = np.array([i[1] for i in PersonD_train_data])\n",
        "\n",
        "X_PersonD_test = np.array([i[0] for i in PersonD_test_data]).reshape(-1, IMG_SIZE,IMG_SIZE, 1)\n",
        "y_PersonD_test = np.array([i[1] for i in PersonD_test_data])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GNz_EPjOihpS"
      },
      "outputs": [],
      "source": [
        "X_PersonE_train = np.array([i[0] for i in PersonE_train_data]).reshape(-1, IMG_SIZE,IMG_SIZE, 1)\n",
        "y_PersonE_train = np.array([i[1] for i in PersonE_train_data])\n",
        "\n",
        "X_PersonE_test = np.array([i[0] for i in PersonE_test_data]).reshape(-1, IMG_SIZE, IMG_SIZE, 1)\n",
        "y_PersonE_test = np.array([i[1] for i in PersonE_test_data])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g04IR4tnSIg6"
      },
      "outputs": [],
      "source": [
        "def create_layers():\n",
        "  ops.reset_default_graph()\n",
        "  conv_input = input_data(shape=[None,IMG_SIZE, IMG_SIZE, 1], name='input')\n",
        "  conv1 = conv_2d(conv_input, 32, 5, activation='relu')\n",
        "  pool1 = max_pool_2d(conv1, 5)\n",
        "\n",
        "  conv2 = conv_2d(pool1, 64, 5, activation='relu')\n",
        "  pool2 = max_pool_2d(conv2, 5)\n",
        "\n",
        "  conv3 = conv_2d(pool2, 128, 5, activation='relu')\n",
        "  pool3 = max_pool_2d(conv3, 5)\n",
        "\n",
        "  conv4 = conv_2d(pool3, 64, 5, activation='relu')\n",
        "  pool4 = max_pool_2d(conv4, 5)\n",
        "\n",
        "  conv5 = conv_2d(pool4, 32, 5, activation='relu')\n",
        "  pool5 = max_pool_2d(conv5, 5)\n",
        "\n",
        "  fully_layer = fully_connected(pool5, 1024, activation='relu')\n",
        "  fully_layer = dropout(fully_layer, 0.5)\n",
        "\n",
        "  cnn_layers = fully_connected(fully_layer, 2, activation='softmax')\n",
        "\n",
        "  cnn_layers = regression(cnn_layers, optimizer='adam', learning_rate=LR, loss='categorical_crossentropy', name='targets')\n",
        "  return cnn_layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0VMH-GsuipZA",
        "outputId": "5048c9c9-fbe0-465d-ed80-9c2f6aba2600"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tflearn/initializations.py:110: calling UniformUnitScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/util/deprecation.py:561: UniformUnitScaling.__init__ (from tensorflow.python.ops.init_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.initializers.variance_scaling instead with distribution=uniform to get equivalent behavior.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tflearn/initializations.py:164: calling TruncatedNormal.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py:1082: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "---------------------------------\n",
            "Run id: fake-vs-real-personA-cnn\n",
            "Log directory: log/\n",
            "---------------------------------\n",
            "Training samples: 40\n",
            "Validation samples: 0\n",
            "--\n",
            "Training Step: 1  | time: 0.872s\n",
            "| Adam | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 40/40\n",
            "--\n",
            "Training Step: 2  | total loss: \u001b[1m\u001b[32m0.61389\u001b[0m\u001b[0m | time: 0.370s\n",
            "| Adam | epoch: 002 | loss: 0.61389 - acc: 0.4275 -- iter: 40/40\n",
            "--\n",
            "Training Step: 3  | total loss: \u001b[1m\u001b[32m0.69359\u001b[0m\u001b[0m | time: 0.368s\n",
            "| Adam | epoch: 003 | loss: 0.69359 - acc: 0.4664 -- iter: 40/40\n",
            "--\n",
            "Training Step: 4  | total loss: \u001b[1m\u001b[32m0.70012\u001b[0m\u001b[0m | time: 0.426s\n",
            "| Adam | epoch: 004 | loss: 0.70012 - acc: 0.5103 -- iter: 40/40\n",
            "--\n",
            "Training Step: 5  | total loss: \u001b[1m\u001b[32m0.67434\u001b[0m\u001b[0m | time: 0.364s\n",
            "| Adam | epoch: 005 | loss: 0.67434 - acc: 0.6590 -- iter: 40/40\n",
            "--\n",
            "Training Step: 6  | total loss: \u001b[1m\u001b[32m0.71908\u001b[0m\u001b[0m | time: 0.372s\n",
            "| Adam | epoch: 006 | loss: 0.71908 - acc: 0.5568 -- iter: 40/40\n",
            "--\n"
          ]
        }
      ],
      "source": [
        "model_A = tflearn.DNN(create_layers(), tensorboard_dir='log', tensorboard_verbose=3)\n",
        "#if (os.path.exists('model_personA.tfl.meta')):\n",
        "  #  model.load('./model_personA.tfl')\n",
        "#else:\n",
        "model_A.fit({'input': X_PersonA_train}, {'targets': y_PersonA_train}, n_epoch=17,  show_metric=True, run_id=MODEL_PersonA_NAME)  \n",
        "model_A.save('model_personA.tfl')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4XywyJkN1Yqi"
      },
      "outputs": [],
      "source": [
        "predictions_A =model_A.predict(X_PersonA_test)\n",
        "print(\"Trueeeee A\")\n",
        "print(y_PersonA_test)\n",
        "\n",
        "A_predictions=[]\n",
        "for i in range(len(predictions_A)):\n",
        "  if predictions_A[i][0]>=predictions_A[i][1]:\n",
        "    A_predictions.append([1,0])\n",
        "  else:\n",
        "    A_predictions.append([0,1])\n",
        "print (\"A predictions\")\n",
        "print(A_predictions)\n",
        "accuracy_A=accuracy_score(y_PersonA_test,A_predictions)\n",
        "print(\"accuracy A:\")\n",
        "print(accuracy_A)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dnFqP1Dxv9h4"
      },
      "outputs": [],
      "source": [
        "model_B = tflearn.DNN(create_layers(), tensorboard_dir='log', tensorboard_verbose=3)\n",
        "#if (os.path.exists('model_personB.tfl.meta')):\n",
        "   # model.load('./model_personB.tfl')\n",
        "#else:\n",
        "model_B.fit({'input': X_PersonB_train}, {'targets': y_PersonB_train}, n_epoch=25,  show_metric=True, run_id=MODEL_PersonB_NAME)  \n",
        "model_B.save('model_personB.tfl')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AG_jtoPUt3Er"
      },
      "outputs": [],
      "source": [
        "predictions_B =model_B.predict(X_PersonB_test)\n",
        "print(\"Trueeeee B\")\n",
        "\n",
        "print(predictions_B)\n",
        "B_predictions=[]\n",
        "for i in range(len(predictions_B)):\n",
        "  if predictions_B[i][0]>=predictions_B[i][1]:\n",
        "    B_predictions.append([1,0])\n",
        "  else:\n",
        "    B_predictions.append([0,1])\n",
        "print (\"B predictions\")\n",
        "print(B_predictions)\n",
        "accuracy_B=accuracy_score(y_PersonB_test,B_predictions)\n",
        "print(\"accuracy B:\")\n",
        "print(accuracy_B)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "utQMc5MkuBjH",
        "outputId": "adc74127-696e-4e6a-fc4d-e1a8ee2811d2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "---------------------------------\n",
            "Run id: fake-vs-real-personC-cnn\n",
            "Log directory: log/\n",
            "---------------------------------\n",
            "Training samples: 40\n",
            "Validation samples: 0\n",
            "--\n",
            "Training Step: 1  | time: 0.703s\n",
            "| Adam | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 40/40\n",
            "--\n",
            "Training Step: 2  | total loss: \u001b[1m\u001b[32m0.64297\u001b[0m\u001b[0m | time: 0.347s\n",
            "| Adam | epoch: 002 | loss: 0.64297 - acc: 0.4500 -- iter: 40/40\n",
            "--\n",
            "Training Step: 3  | total loss: \u001b[1m\u001b[32m0.69492\u001b[0m\u001b[0m | time: 0.371s\n",
            "| Adam | epoch: 003 | loss: 0.69492 - acc: 0.4705 -- iter: 40/40\n",
            "--\n",
            "Training Step: 4  | total loss: \u001b[1m\u001b[32m0.70674\u001b[0m\u001b[0m | time: 0.423s\n",
            "| Adam | epoch: 004 | loss: 0.70674 - acc: 0.4926 -- iter: 40/40\n",
            "--\n",
            "Training Step: 5  | total loss: \u001b[1m\u001b[32m0.70178\u001b[0m\u001b[0m | time: 0.647s\n",
            "| Adam | epoch: 005 | loss: 0.70178 - acc: 0.4285 -- iter: 40/40\n",
            "--\n",
            "Training Step: 6  | total loss: \u001b[1m\u001b[32m0.69238\u001b[0m\u001b[0m | time: 0.779s\n",
            "| Adam | epoch: 006 | loss: 0.69238 - acc: 0.5066 -- iter: 40/40\n",
            "--\n",
            "Training Step: 7  | total loss: \u001b[1m\u001b[32m0.69606\u001b[0m\u001b[0m | time: 0.789s\n",
            "| Adam | epoch: 007 | loss: 0.69606 - acc: 0.4876 -- iter: 40/40\n",
            "--\n",
            "Training Step: 8  | total loss: \u001b[1m\u001b[32m0.70467\u001b[0m\u001b[0m | time: 0.631s\n",
            "| Adam | epoch: 008 | loss: 0.70467 - acc: 0.4243 -- iter: 40/40\n",
            "--\n",
            "Training Step: 9  | total loss: \u001b[1m\u001b[32m0.70740\u001b[0m\u001b[0m | time: 0.707s\n",
            "| Adam | epoch: 009 | loss: 0.70740 - acc: 0.4511 -- iter: 40/40\n",
            "--\n",
            "Training Step: 10  | total loss: \u001b[1m\u001b[32m0.70467\u001b[0m\u001b[0m | time: 0.670s\n",
            "| Adam | epoch: 010 | loss: 0.70467 - acc: 0.4256 -- iter: 40/40\n",
            "--\n",
            "Training Step: 11  | total loss: \u001b[1m\u001b[32m0.70156\u001b[0m\u001b[0m | time: 0.721s\n",
            "| Adam | epoch: 011 | loss: 0.70156 - acc: 0.4727 -- iter: 40/40\n",
            "--\n",
            "Training Step: 12  | total loss: \u001b[1m\u001b[32m0.69693\u001b[0m\u001b[0m | time: 0.642s\n",
            "| Adam | epoch: 012 | loss: 0.69693 - acc: 0.4962 -- iter: 40/40\n",
            "--\n",
            "Training Step: 13  | total loss: \u001b[1m\u001b[32m0.69111\u001b[0m\u001b[0m | time: 0.666s\n",
            "| Adam | epoch: 013 | loss: 0.69111 - acc: 0.5514 -- iter: 40/40\n",
            "--\n",
            "Training Step: 14  | total loss: \u001b[1m\u001b[32m0.69204\u001b[0m\u001b[0m | time: 0.725s\n",
            "| Adam | epoch: 014 | loss: 0.69204 - acc: 0.5304 -- iter: 40/40\n",
            "--\n",
            "Training Step: 15  | total loss: \u001b[1m\u001b[32m0.69102\u001b[0m\u001b[0m | time: 0.713s\n",
            "| Adam | epoch: 015 | loss: 0.69102 - acc: 0.5283 -- iter: 40/40\n",
            "--\n"
          ]
        }
      ],
      "source": [
        "model_C = tflearn.DNN(create_layers(), tensorboard_dir='log', tensorboard_verbose=3)\n",
        "#if (os.path.exists('model_personC.tfl.meta')):\n",
        "   # model.load('./model_personC.tfl')\n",
        "#else:\n",
        "model_C.fit({'input': X_PersonC_train}, {'targets': y_PersonC_train}, n_epoch=15,  show_metric=True, run_id=MODEL_PersonC_NAME)  \n",
        "model_C.save('model_personC.tfl')\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "hBgxkRFHNhwa",
        "outputId": "eff2b955-46c9-4dc4-dcd2-3789d65ab89a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Trueeeee c\n",
            "[[0 1]\n",
            " [0 1]\n",
            " [1 0]\n",
            " [0 1]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [0 1]\n",
            " [1 0]]\n",
            "C predictions\n",
            "[[0, 1], [0, 1], [0, 1], [0, 1], [0, 1], [0, 1], [0, 1], [0, 1]]\n",
            "accuracy C:\n",
            "0.5\n"
          ]
        }
      ],
      "source": [
        "predictions_C =model_C.predict(X_PersonC_test)\n",
        "print(\"Trueeeee c\")\n",
        "print(y_PersonC_test)\n",
        "\n",
        "C_predictions=[]\n",
        "for i in range(len(predictions_C)):\n",
        "  if predictions_C[i][0]>=predictions_C[i][1]:\n",
        "    C_predictions.append([1,0])\n",
        "  else:\n",
        "    C_predictions.append([0,1])\n",
        "print (\"C predictions\")\n",
        "print(C_predictions)\n",
        "accuracy_C=accuracy_score(y_PersonC_test,C_predictions)\n",
        "print(\"accuracy C:\")\n",
        "print(accuracy_C)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "n7Pud2PWuDRk",
        "outputId": "1aa50f1a-6023-4c58-d000-e47be9568386"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "---------------------------------\n",
            "Run id: fake-vs-real-personD-cnn\n",
            "Log directory: log/\n",
            "---------------------------------\n",
            "Training samples: 40\n",
            "Validation samples: 0\n",
            "--\n",
            "Training Step: 1  | time: 0.666s\n",
            "| Adam | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 40/40\n",
            "--\n",
            "Training Step: 2  | total loss: \u001b[1m\u001b[32m0.62652\u001b[0m\u001b[0m | time: 0.340s\n",
            "| Adam | epoch: 002 | loss: 0.62652 - acc: 0.4050 -- iter: 40/40\n",
            "--\n",
            "Training Step: 3  | total loss: \u001b[1m\u001b[32m0.69105\u001b[0m\u001b[0m | time: 0.354s\n",
            "| Adam | epoch: 003 | loss: 0.69105 - acc: 0.4827 -- iter: 40/40\n",
            "--\n",
            "Training Step: 4  | total loss: \u001b[1m\u001b[32m0.68676\u001b[0m\u001b[0m | time: 0.358s\n",
            "| Adam | epoch: 004 | loss: 0.68676 - acc: 0.5519 -- iter: 40/40\n",
            "--\n",
            "Training Step: 5  | total loss: \u001b[1m\u001b[32m0.67657\u001b[0m\u001b[0m | time: 0.350s\n",
            "| Adam | epoch: 005 | loss: 0.67657 - acc: 0.5852 -- iter: 40/40\n",
            "--\n",
            "Training Step: 6  | total loss: \u001b[1m\u001b[32m0.70378\u001b[0m\u001b[0m | time: 0.352s\n",
            "| Adam | epoch: 006 | loss: 0.70378 - acc: 0.5465 -- iter: 40/40\n",
            "--\n",
            "Training Step: 7  | total loss: \u001b[1m\u001b[32m0.72894\u001b[0m\u001b[0m | time: 0.359s\n",
            "| Adam | epoch: 007 | loss: 0.72894 - acc: 0.4586 -- iter: 40/40\n",
            "--\n",
            "Training Step: 8  | total loss: \u001b[1m\u001b[32m0.72663\u001b[0m\u001b[0m | time: 0.351s\n",
            "| Adam | epoch: 008 | loss: 0.72663 - acc: 0.5241 -- iter: 40/40\n",
            "--\n",
            "Training Step: 9  | total loss: \u001b[1m\u001b[32m0.70430\u001b[0m\u001b[0m | time: 0.358s\n",
            "| Adam | epoch: 009 | loss: 0.70430 - acc: 0.5643 -- iter: 40/40\n",
            "--\n",
            "Training Step: 10  | total loss: \u001b[1m\u001b[32m0.70141\u001b[0m\u001b[0m | time: 0.340s\n",
            "| Adam | epoch: 010 | loss: 0.70141 - acc: 0.5071 -- iter: 40/40\n",
            "--\n",
            "Training Step: 11  | total loss: \u001b[1m\u001b[32m0.70393\u001b[0m\u001b[0m | time: 0.341s\n",
            "| Adam | epoch: 011 | loss: 0.70393 - acc: 0.4801 -- iter: 40/40\n",
            "--\n",
            "Training Step: 12  | total loss: \u001b[1m\u001b[32m0.70167\u001b[0m\u001b[0m | time: 0.370s\n",
            "| Adam | epoch: 012 | loss: 0.70167 - acc: 0.4778 -- iter: 40/40\n",
            "--\n",
            "Training Step: 13  | total loss: \u001b[1m\u001b[32m0.70235\u001b[0m\u001b[0m | time: 0.355s\n",
            "| Adam | epoch: 013 | loss: 0.70235 - acc: 0.4659 -- iter: 40/40\n",
            "--\n",
            "Training Step: 14  | total loss: \u001b[1m\u001b[32m0.69904\u001b[0m\u001b[0m | time: 0.348s\n",
            "| Adam | epoch: 014 | loss: 0.69904 - acc: 0.5207 -- iter: 40/40\n",
            "--\n",
            "Training Step: 15  | total loss: \u001b[1m\u001b[32m0.69512\u001b[0m\u001b[0m | time: 0.360s\n",
            "| Adam | epoch: 015 | loss: 0.69512 - acc: 0.5615 -- iter: 40/40\n",
            "--\n",
            "Training Step: 16  | total loss: \u001b[1m\u001b[32m0.70058\u001b[0m\u001b[0m | time: 0.336s\n",
            "| Adam | epoch: 016 | loss: 0.70058 - acc: 0.5197 -- iter: 40/40\n",
            "--\n",
            "Training Step: 17  | total loss: \u001b[1m\u001b[32m0.69709\u001b[0m\u001b[0m | time: 0.347s\n",
            "| Adam | epoch: 017 | loss: 0.69709 - acc: 0.5216 -- iter: 40/40\n",
            "--\n",
            "Training Step: 18  | total loss: \u001b[1m\u001b[32m0.69214\u001b[0m\u001b[0m | time: 0.354s\n",
            "| Adam | epoch: 018 | loss: 0.69214 - acc: 0.5401 -- iter: 40/40\n",
            "--\n",
            "Training Step: 19  | total loss: \u001b[1m\u001b[32m0.68423\u001b[0m\u001b[0m | time: 0.340s\n",
            "| Adam | epoch: 019 | loss: 0.68423 - acc: 0.6101 -- iter: 40/40\n",
            "--\n",
            "Training Step: 20  | total loss: \u001b[1m\u001b[32m0.67492\u001b[0m\u001b[0m | time: 0.359s\n",
            "| Adam | epoch: 020 | loss: 0.67492 - acc: 0.6149 -- iter: 40/40\n",
            "--\n",
            "Training Step: 21  | total loss: \u001b[1m\u001b[32m0.66177\u001b[0m\u001b[0m | time: 0.369s\n",
            "| Adam | epoch: 021 | loss: 0.66177 - acc: 0.6646 -- iter: 40/40\n",
            "--\n",
            "Training Step: 22  | total loss: \u001b[1m\u001b[32m0.64852\u001b[0m\u001b[0m | time: 0.347s\n",
            "| Adam | epoch: 022 | loss: 0.64852 - acc: 0.6752 -- iter: 40/40\n",
            "--\n",
            "Training Step: 23  | total loss: \u001b[1m\u001b[32m0.62561\u001b[0m\u001b[0m | time: 0.349s\n",
            "| Adam | epoch: 023 | loss: 0.62561 - acc: 0.7259 -- iter: 40/40\n",
            "--\n",
            "Training Step: 24  | total loss: \u001b[1m\u001b[32m0.60068\u001b[0m\u001b[0m | time: 0.360s\n",
            "| Adam | epoch: 024 | loss: 0.60068 - acc: 0.7327 -- iter: 40/40\n",
            "--\n",
            "Training Step: 25  | total loss: \u001b[1m\u001b[32m0.57314\u001b[0m\u001b[0m | time: 0.338s\n",
            "| Adam | epoch: 025 | loss: 0.57314 - acc: 0.7579 -- iter: 40/40\n",
            "--\n"
          ]
        }
      ],
      "source": [
        "model_D = tflearn.DNN(create_layers(), tensorboard_dir='log', tensorboard_verbose=3)\n",
        "#if (os.path.exists('model_personD.tfl.meta')):\n",
        "    #model.load('./model_personD.tfl')\n",
        "#else:\n",
        "model_D.fit({'input': X_PersonD_train}, {'targets': y_PersonD_train}, n_epoch=25, show_metric=True, run_id=MODEL_PersonD_NAME)  \n",
        "model_D.save('model_personD.tfl')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "czI8n71OOhkZ",
        "outputId": "26770b75-1a63-4735-a3bc-6c1944d77ca3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Trueeeee D\n",
            "[[1 0]\n",
            " [1 0]\n",
            " [0 1]\n",
            " [1 0]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [1 0]\n",
            " [0 1]]\n",
            "D predictions\n",
            "[[1, 0], [0, 1], [0, 1], [1, 0], [0, 1], [1, 0], [0, 1], [0, 1]]\n",
            "accuracy D:\n",
            "0.625\n"
          ]
        }
      ],
      "source": [
        "predictions_D =model_D.predict(X_PersonD_test)\n",
        "print(\"Trueeeee D\")\n",
        "print(y_PersonD_test)\n",
        "\n",
        "D_predictions=[]\n",
        "for i in range(len(predictions_D)):\n",
        "  if predictions_D[i][0]>=predictions_D[i][1]:\n",
        "    D_predictions.append([1,0])\n",
        "  else:\n",
        "    D_predictions.append([0,1])\n",
        "print (\"D predictions\")\n",
        "print(D_predictions)\n",
        "accuracy_D=accuracy_score(y_PersonD_test,D_predictions)\n",
        "print(\"accuracy D:\")\n",
        "print(accuracy_D)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "yQb1OEHguFpO",
        "outputId": "57f0dd3a-70af-4880-9201-80e8efc362bc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "---------------------------------\n",
            "Run id: fake-vs-real-personE-cnn\n",
            "Log directory: log/\n",
            "---------------------------------\n",
            "Training samples: 50\n",
            "Validation samples: 0\n",
            "--\n",
            "Training Step: 1  | time: 0.761s\n",
            "| Adam | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 50/50\n",
            "--\n",
            "Training Step: 2  | total loss: \u001b[1m\u001b[32m0.62540\u001b[0m\u001b[0m | time: 0.427s\n",
            "| Adam | epoch: 002 | loss: 0.62540 - acc: 0.5040 -- iter: 50/50\n",
            "--\n",
            "Training Step: 3  | total loss: \u001b[1m\u001b[32m0.67774\u001b[0m\u001b[0m | time: 0.418s\n",
            "| Adam | epoch: 003 | loss: 0.67774 - acc: 0.5662 -- iter: 50/50\n",
            "--\n",
            "Training Step: 4  | total loss: \u001b[1m\u001b[32m0.67537\u001b[0m\u001b[0m | time: 0.416s\n",
            "| Adam | epoch: 004 | loss: 0.67537 - acc: 0.5915 -- iter: 50/50\n",
            "--\n",
            "Training Step: 5  | total loss: \u001b[1m\u001b[32m0.67043\u001b[0m\u001b[0m | time: 0.430s\n",
            "| Adam | epoch: 005 | loss: 0.67043 - acc: 0.5974 -- iter: 50/50\n",
            "--\n",
            "Training Step: 6  | total loss: \u001b[1m\u001b[32m0.67365\u001b[0m\u001b[0m | time: 0.412s\n",
            "| Adam | epoch: 006 | loss: 0.67365 - acc: 0.5991 -- iter: 50/50\n",
            "--\n",
            "Training Step: 7  | total loss: \u001b[1m\u001b[32m0.66632\u001b[0m\u001b[0m | time: 0.433s\n",
            "| Adam | epoch: 007 | loss: 0.66632 - acc: 0.6236 -- iter: 50/50\n",
            "--\n",
            "Training Step: 8  | total loss: \u001b[1m\u001b[32m0.67290\u001b[0m\u001b[0m | time: 0.414s\n",
            "| Adam | epoch: 008 | loss: 0.67290 - acc: 0.6103 -- iter: 50/50\n",
            "--\n",
            "Training Step: 9  | total loss: \u001b[1m\u001b[32m0.66542\u001b[0m\u001b[0m | time: 0.421s\n",
            "| Adam | epoch: 009 | loss: 0.66542 - acc: 0.6049 -- iter: 50/50\n",
            "--\n",
            "Training Step: 10  | total loss: \u001b[1m\u001b[32m0.66318\u001b[0m\u001b[0m | time: 0.420s\n",
            "| Adam | epoch: 010 | loss: 0.66318 - acc: 0.6024 -- iter: 50/50\n",
            "--\n",
            "Training Step: 11  | total loss: \u001b[1m\u001b[32m0.64576\u001b[0m\u001b[0m | time: 0.429s\n",
            "| Adam | epoch: 011 | loss: 0.64576 - acc: 0.6013 -- iter: 50/50\n",
            "--\n",
            "Training Step: 12  | total loss: \u001b[1m\u001b[32m0.66789\u001b[0m\u001b[0m | time: 0.436s\n",
            "| Adam | epoch: 012 | loss: 0.66789 - acc: 0.6097 -- iter: 50/50\n",
            "--\n",
            "Training Step: 13  | total loss: \u001b[1m\u001b[32m0.63562\u001b[0m\u001b[0m | time: 0.410s\n",
            "| Adam | epoch: 013 | loss: 0.63562 - acc: 0.6055 -- iter: 50/50\n",
            "--\n",
            "Training Step: 14  | total loss: \u001b[1m\u001b[32m0.67313\u001b[0m\u001b[0m | time: 0.407s\n",
            "| Adam | epoch: 014 | loss: 0.67313 - acc: 0.5705 -- iter: 50/50\n",
            "--\n",
            "Training Step: 15  | total loss: \u001b[1m\u001b[32m0.62274\u001b[0m\u001b[0m | time: 0.413s\n",
            "| Adam | epoch: 015 | loss: 0.62274 - acc: 0.6838 -- iter: 50/50\n",
            "--\n",
            "elhamduallah\n"
          ]
        }
      ],
      "source": [
        "\n",
        "model_E = tflearn.DNN(create_layers(), tensorboard_dir='log', tensorboard_verbose=3)\n",
        "#if (os.path.exists('model_personE.tfl.meta')):\n",
        "   # model.load('./model_personE.tfl')\n",
        "#else:\n",
        "model_E.fit({'input': X_PersonE_train}, {'targets': y_PersonE_train}, n_epoch=15,  show_metric=True, run_id=MODEL_PersonE_NAME)  \n",
        "model_E.save('model_personE.tfl')\n",
        "print(\"elhamduallah\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "IyZAoPvHJQx8",
        "outputId": "4d6ea9c1-c9d5-491a-ff54-132c83a44d74"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Trueeeee E\n",
            "[[1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [0 1]\n",
            " [1 0]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [0 1]]\n",
            "E predictions\n",
            "[[0, 1], [1, 0], [1, 0], [0, 1], [0, 1], [0, 1], [0, 1], [0, 1]]\n",
            "accuracy E:\n",
            "0.75\n"
          ]
        }
      ],
      "source": [
        "predictions_E =model_E.predict(X_PersonE_test)\n",
        "print(\"Trueeeee E\")\n",
        "print(y_PersonE_test)\n",
        "\n",
        "E_predictions=[]\n",
        "for i in range(len(predictions_E)):\n",
        "  if predictions_E[i][0]>=predictions_E[i][1]:\n",
        "    E_predictions.append([1,0])\n",
        "  else:\n",
        "    E_predictions.append([0,1])\n",
        "print (\"E predictions\")\n",
        "print(E_predictions)\n",
        "accuracy_E=accuracy_score(y_PersonE_test,E_predictions)\n",
        "print(\"accuracy E:\")\n",
        "print(accuracy_E)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "TNdgpMUyaMml"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "qgpAQ-vARzIB",
        "outputId": "6b3c9411-38c1-4216-a129-90cb5da4a58b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Archive:  /content/Signature.zip\n",
            "  inflating: Signature/personC_forged.png  \n",
            "  inflating: Signature/personC_real.png  \n",
            "  inflating: Signature/personE_forged.png  \n",
            "  inflating: Signature/personE_real.png  \n",
            "  inflating: Signature/personE_real2.png  \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/5 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-39-ed3ba4c79929>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     40\u001b[0m   \u001b[0;32melif\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0mimg_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m     \u001b[0mmodel_B\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/model_personB.tfl'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m     \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_B\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tflearn/models/dnn.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(self, model_file, weights_only, **optargs)\u001b[0m\n\u001b[1;32m    300\u001b[0m                      \u001b[0mcreated\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mrestored\u001b[0m \u001b[0mvariables\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m         \"\"\"\n\u001b[0;32m--> 302\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights_only\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moptargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    303\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m         self.predictor = Evaluator([self.net],\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tflearn/helpers/trainer.py\u001b[0m in \u001b[0;36mrestore\u001b[0;34m(self, model_file, trainable_variable_only, variable_name_map, scope_for_restore, create_new_session, verbose)\u001b[0m\n\u001b[1;32m    506\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    507\u001b[0m         \u001b[0;31m# Restore the training step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 508\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglobal_step\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    509\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/ops/variables.py\u001b[0m in \u001b[0;36meval\u001b[0;34m(self, session)\u001b[0m\n\u001b[1;32m   2005\u001b[0m       \u001b[0mA\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0ma\u001b[0m \u001b[0mcopy\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthis\u001b[0m \u001b[0mvariable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2006\u001b[0m     \"\"\"\n\u001b[0;32m-> 2007\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2008\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2009\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36meval\u001b[0;34m(self, feed_dict, session)\u001b[0m\n\u001b[1;32m    993\u001b[0m       \u001b[0mA\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0marray\u001b[0m \u001b[0mcorresponding\u001b[0m \u001b[0mto\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthis\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    994\u001b[0m     \"\"\"\n\u001b[0;32m--> 995\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_eval_using_default_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    996\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    997\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mdeprecation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeprecated\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Use ref() instead.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_eval_using_default_session\u001b[0;34m(tensors, feed_dict, graph, session)\u001b[0m\n\u001b[1;32m   5742\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5743\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5744\u001b[0;31m       raise ValueError(\"Cannot use the given session to evaluate tensor: \"\n\u001b[0m\u001b[1;32m   5745\u001b[0m                        \u001b[0;34m\"the tensor's graph is different from the session's \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5746\u001b[0m                        \"graph.\")\n",
            "\u001b[0;31mValueError\u001b[0m: Cannot use the given session to evaluate tensor: the tensor's graph is different from the session's graph."
          ]
        }
      ],
      "source": [
        "###############Test Script#################\n",
        "from joblib import Parallel, delayed\n",
        "import joblib\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "!unzip '/content/Signature.zip'\n",
        "path = '/content/Signature'\n",
        "SVM = joblib.load('/content/SVM.pkl')\n",
        "Kmeans = joblib.load('/content/Kmeans.pkl')\n",
        "Scaler = joblib.load('/content/Scaler.pkl')\n",
        "for img in tqdm(os.listdir(path)):\n",
        "  img_data = cv2.imread(os.path.join(path, img), 0)\n",
        "  ############recognizer############\n",
        "  sift_object = cv2.xfeatures2d.SIFT_create()\n",
        "  kp, des = sift_object.detectAndCompute(img_data, None)\n",
        "  vocab = np.array( [[ 0 for i in range(100)]])\n",
        "  vocab = np.array(vocab, 'float32')\n",
        "  kmeanRet = Kmeans.predict(des)\n",
        "  for each in kmeanRet:\n",
        "      vocab[0][each] += 1\n",
        "  vocab = Scaler.transform(vocab)\n",
        "  label = SVM.predict(vocab) \n",
        "  ##########check real or forged############\n",
        "  if label == 0:\n",
        "    img_data = cv2.resize(img_data, (50,50))\n",
        "    model_A.load('/content/model_personA.tfl')\n",
        "    state = model_A.predict(img)\n",
        "    if state[0] == 1:\n",
        "      plt.imshow(cv2.cvtColor(img_data, cv2.COLOR_GRAY2RGB))\n",
        "      plt.title(\"person A real\")\n",
        "      plt.show()\n",
        "    else:\n",
        "      plt.imshow(cv2.cvtColor(img_data, cv2.COLOR_GRAY2RGB))\n",
        "      plt.title(\"person A forged\")\n",
        "      plt.show()\n",
        "  elif label == 1:\n",
        "    img_data = cv2.resize(img_data, (50,50))\n",
        "    model_B.load('/content/model_personB.tfl')\n",
        "    state = model_B.predict(img)\n",
        "    if state[0] == 1:\n",
        "      plt.imshow(cv2.cvtColor(img_data, cv2.COLOR_GRAY2RGB))\n",
        "      plt.title(\"person B real\")\n",
        "      plt.show()\n",
        "    else:\n",
        "      plt.imshow(cv2.cvtColor(img_data, cv2.COLOR_GRAY2RGB))\n",
        "      plt.title(\"person B forged\")\n",
        "      plt.show()\n",
        "  elif label == 2:\n",
        "    img_data = cv2.resize(img_data, (50,50))\n",
        "    model_C.load('/content/model_personC.tfl')\n",
        "    state = model_C.predict(img)\n",
        "    if state[0] == 1:\n",
        "      plt.imshow(cv2.cvtColor(img_data, cv2.COLOR_GRAY2RGB))\n",
        "      plt.title(\"person C real\")\n",
        "      plt.show()\n",
        "    else:\n",
        "      plt.imshow(cv2.cvtColor(img_data, cv2.COLOR_GRAY2RGB))\n",
        "      plt.title(\"person C forged\")\n",
        "      plt.show()\n",
        "  elif label == 3:\n",
        "    img_data = cv2.resize(img_data, (50,50))\n",
        "    model_D.load('/content/model_personD.tfl')\n",
        "    state = model_D.predict(img)\n",
        "    if state[0] == 1:\n",
        "      plt.imshow(cv2.cvtColor(img_data, cv2.COLOR_GRAY2RGB))\n",
        "      plt.title(\"person D real\")\n",
        "      plt.show()\n",
        "    else:\n",
        "      plt.imshow(cv2.cvtColor(img_data, cv2.COLOR_GRAY2RGB))\n",
        "      plt.title(\"person D forged\")\n",
        "      plt.show()\n",
        "  elif label == 4:\n",
        "    img_data = cv2.resize(img_data, (50,50))\n",
        "    model_E.load_model('/content/model_personA.tfl')\n",
        "    state = model_E.predict(img_data)\n",
        "    if state[0] == 1:\n",
        "      plt.imshow(cv2.cvtColor(img_data, cv2.COLOR_GRAY2RGB))\n",
        "      plt.title(\"person E real\")\n",
        "      plt.show()\n",
        "    else:\n",
        "      plt.imshow(cv2.cvtColor(img_data, cv2.COLOR_GRAY2RGB))\n",
        "      plt.title(\"person E forged\")\n",
        "      plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}